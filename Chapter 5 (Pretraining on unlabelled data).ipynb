{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2396085-897d-4501-9add-5487fd651a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretraining on unlabeled data\n",
    "#Evaluating generative text models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da91c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7bc323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133bd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous chapters imported\n",
    "# CHAPTER 2\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        #Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        #Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i+1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids) \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    #Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    \n",
    "    #Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    \n",
    "    #Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "#  CHAPTER 3\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert( d_out % num_heads == 0 ), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        #Shape: (b, num_tokens, d_out)\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        #We implicitly split the matrix by adding a num_heads dimension\n",
    "        #Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        #Compute scaled dot product attention (aka self attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3) #Dot product for each head\n",
    "        #Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        #Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        #Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        #Combine heads, where self.d_out = elf.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) #Optional Projection\n",
    "        return context_vec\n",
    "\n",
    "# CHAPTER 4\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "                torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "                (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) #Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut #Add the original input back\n",
    "\n",
    "        #Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut #Add the original input back\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "     # Automatically move the input tensor to the model's device (e.g., \"cuda\")\n",
    "    device = next(model.parameters()).device\n",
    "    idx = idx.to(device)\n",
    "                 \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e9f298-f333-44e7-b260-5b7cab897f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "tensorflow version: 2.16.1\n",
      "matplotlib version: 3.8.4\n",
      "torch version: 2.5.1+cu121\n",
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "#Using GPT to generate text\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = {\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\" #For OpenAI's Pretrained weights\n",
    "       }\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1521cef0-1954-405e-b1da-abd7a31473e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, #Vocabulary size\n",
    "    \"context_length\": 256, #Context length\n",
    "    \"emb_dim\": 768, #Embedding Dimension\n",
    "    \"n_heads\": 12, #Number of attention heads\n",
    "    \"n_layers\": 12, #Number of layers\n",
    "    \"drop_rate\": 0.1, #Dropout rate\n",
    "    \"qkv_bias\": False #Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df0240c-5aee-43f0-a3eb-383d2d48c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() #Disabling dropout so no random dropping during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d166ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a21d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a43f895-5d25-4dbe-a22b-1914995bf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); #Disabling dropout so no random dropping during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db574d8-65d2-4986-800e-d2f0b8455fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) #Add bacth dimension\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a419616c-8b1f-48aa-9880-8f0208b13adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = text_to_token_ids(start_context, tokenizer)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b3d577-1c08-4536-97e3-c06d4e490193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f358b0ed-1de9-4ab6-b3a2-7ffba5ce1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3cb6e6-ea01-4dbe-9316-dba9c4c85d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2f1942-767b-418e-b19f-b4a072dd2d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "493d0193-90e5-433a-9e90-ecd28a670d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f12f5f77-efd5-4dc1-b88d-69de34ac91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1a8b68-0c82-476e-9910-223e75349f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], #every effort moves\n",
    "                      [40, 1107, 588]])     #I really like\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],  #effort moves you\n",
    "                       [1107, 588, 11311]]) #really like chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b238480-e03a-491b-9ee7-990801b14412",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67726e1-ea93-470a-837f-92ca565249c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4bc7847-f820-4a63-917d-55b05cbf3b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "536a9de1-5603-4b10-b90b-38f10f3bbc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
       "          6.9776e-06, 1.8776e-05],\n",
       "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
       "          6.0103e-06, 1.3571e-05],\n",
       "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
       "          1.4094e-05, 1.3526e-05]],\n",
       "\n",
       "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
       "          3.4784e-05, 1.4239e-05],\n",
       "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
       "          1.1390e-05, 1.5559e-05],\n",
       "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
       "          5.8203e-05, 1.3698e-05]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aac5822e-2cba-4dc7-b434-c543bde66992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.0000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1a9d9b6-e03e-4f1c-bcbe-6d5953c80e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54d0c553-e826-4fd4-a693-e22a9bf0a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42a9cfd-bc55-4aca-b660-63edf2b3672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76f64d08-edec-4861-bd53-47ee3de4ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3626, 6100,  345])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[text_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd24d3e0-6781-4ed9-be6d-794d717a40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "854a7715-6693-44ee-a56b-bc957331e4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1107,   588, 11311])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[text_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4940f234-5894-43f3-aaf5-d364d400dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "#Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc34195f-8b99-484d-a62a-97a99e0c796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7940)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65548fa0-9c56-4609-9786-01d2e3c4610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*torch.mean(log_probas) #Cross-Entropy loss , our aim is to brin it as close to 0 as we can during the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b896901a-cb0b-4722-89d8-96e15d065627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21f28e6d-6030-4e31-af14-62571c92c48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a0d48cb-dcc4-42ec-a39f-7179bad2052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de981ae3-cbcd-44af-823f-10516569b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat = targets.flatten()\n",
    "targets_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e31011c-a749-4322-b54c-9aea5485030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc340df1-5f29-4e7f-bade-c58ad7e4b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44dce9cb-7513-4d9d-be14-1ceb0d08c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict-txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "080e90f1-6fce-4703-896f-f5edc4c93d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e68c6fd5-e360-420c-8591-a449f7c3e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "596dde38-df5a-4fed-b860-40405e204cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40,\n",
       " 367,\n",
       " 2885,\n",
       " 1464,\n",
       " 1807,\n",
       " 3619,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 2138,\n",
       " 257,\n",
       " 7026,\n",
       " 15632,\n",
       " 438,\n",
       " 2016,\n",
       " 257,\n",
       " 922,\n",
       " 5891,\n",
       " 1576,\n",
       " 438,\n",
       " 568,\n",
       " 340,\n",
       " 373,\n",
       " 645,\n",
       " 1049,\n",
       " 5975,\n",
       " 284,\n",
       " 502,\n",
       " 284,\n",
       " 3285,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 6001,\n",
       " 286,\n",
       " 465,\n",
       " 13476,\n",
       " 11,\n",
       " 339,\n",
       " 550,\n",
       " 5710,\n",
       " 465,\n",
       " 12036,\n",
       " 11,\n",
       " 6405,\n",
       " 257,\n",
       " 5527,\n",
       " 27075,\n",
       " 11,\n",
       " 290,\n",
       " 4920,\n",
       " 2241,\n",
       " 287,\n",
       " 257,\n",
       " 4489,\n",
       " 64,\n",
       " 319,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 13,\n",
       " 357,\n",
       " 10915,\n",
       " 314,\n",
       " 2138,\n",
       " 1807,\n",
       " 340,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 10598,\n",
       " 393,\n",
       " 28537,\n",
       " 2014,\n",
       " 198,\n",
       " 198,\n",
       " 1,\n",
       " 464,\n",
       " 6001,\n",
       " 286,\n",
       " 465,\n",
       " 13476,\n",
       " 1,\n",
       " 438,\n",
       " 5562,\n",
       " 373,\n",
       " 644,\n",
       " 262,\n",
       " 1466,\n",
       " 1444,\n",
       " 340,\n",
       " 13,\n",
       " 314,\n",
       " 460,\n",
       " 3285,\n",
       " 9074,\n",
       " 13,\n",
       " 46606,\n",
       " 536,\n",
       " 5469,\n",
       " 438,\n",
       " 14363,\n",
       " 938,\n",
       " 4842,\n",
       " 1650,\n",
       " 353,\n",
       " 438,\n",
       " 2934,\n",
       " 489,\n",
       " 3255,\n",
       " 465,\n",
       " 48422,\n",
       " 540,\n",
       " 450,\n",
       " 67,\n",
       " 3299,\n",
       " 13,\n",
       " 366,\n",
       " 5189,\n",
       " 1781,\n",
       " 340,\n",
       " 338,\n",
       " 1016,\n",
       " 284,\n",
       " 3758,\n",
       " 262,\n",
       " 1988,\n",
       " 286,\n",
       " 616,\n",
       " 4286,\n",
       " 705,\n",
       " 1014,\n",
       " 510,\n",
       " 26,\n",
       " 475,\n",
       " 314,\n",
       " 836,\n",
       " 470,\n",
       " 892,\n",
       " 286,\n",
       " 326,\n",
       " 11,\n",
       " 1770,\n",
       " 13,\n",
       " 8759,\n",
       " 2763,\n",
       " 438,\n",
       " 1169,\n",
       " 2994,\n",
       " 284,\n",
       " 943,\n",
       " 17034,\n",
       " 318,\n",
       " 477,\n",
       " 314,\n",
       " 892,\n",
       " 286,\n",
       " 526,\n",
       " 383,\n",
       " 1573,\n",
       " 11,\n",
       " 319,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 5469,\n",
       " 338,\n",
       " 11914,\n",
       " 11,\n",
       " 33096,\n",
       " 663,\n",
       " 4808,\n",
       " 3808,\n",
       " 62,\n",
       " 355,\n",
       " 996,\n",
       " 484,\n",
       " 547,\n",
       " 12548,\n",
       " 287,\n",
       " 281,\n",
       " 13079,\n",
       " 410,\n",
       " 12523,\n",
       " 286,\n",
       " 22353,\n",
       " 13,\n",
       " 843,\n",
       " 340,\n",
       " 373,\n",
       " 407,\n",
       " 691,\n",
       " 262,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 48819,\n",
       " 508,\n",
       " 25722,\n",
       " 276,\n",
       " 13,\n",
       " 11161,\n",
       " 407,\n",
       " 262,\n",
       " 40123,\n",
       " 18113,\n",
       " 544,\n",
       " 9325,\n",
       " 701,\n",
       " 11,\n",
       " 379,\n",
       " 262,\n",
       " 938,\n",
       " 402,\n",
       " 1617,\n",
       " 261,\n",
       " 12917,\n",
       " 905,\n",
       " 11,\n",
       " 5025,\n",
       " 502,\n",
       " 878,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 366,\n",
       " 31640,\n",
       " 12,\n",
       " 67,\n",
       " 20811,\n",
       " 1,\n",
       " 284,\n",
       " 910,\n",
       " 11,\n",
       " 351,\n",
       " 10953,\n",
       " 287,\n",
       " 607,\n",
       " 2951,\n",
       " 25,\n",
       " 366,\n",
       " 1135,\n",
       " 2236,\n",
       " 407,\n",
       " 804,\n",
       " 2402,\n",
       " 663,\n",
       " 588,\n",
       " 757,\n",
       " 13984,\n",
       " 198,\n",
       " 198,\n",
       " 5779,\n",
       " 28112,\n",
       " 10197,\n",
       " 832,\n",
       " 262,\n",
       " 46475,\n",
       " 286,\n",
       " 18113,\n",
       " 544,\n",
       " 338,\n",
       " 10953,\n",
       " 314,\n",
       " 2936,\n",
       " 1498,\n",
       " 284,\n",
       " 1986,\n",
       " 262,\n",
       " 1109,\n",
       " 351,\n",
       " 1602,\n",
       " 11227,\n",
       " 414,\n",
       " 13,\n",
       " 23676,\n",
       " 3619,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 0,\n",
       " 383,\n",
       " 1466,\n",
       " 550,\n",
       " 925,\n",
       " 683,\n",
       " 438,\n",
       " 270,\n",
       " 373,\n",
       " 15830,\n",
       " 326,\n",
       " 484,\n",
       " 815,\n",
       " 25722,\n",
       " 683,\n",
       " 13,\n",
       " 9754,\n",
       " 465,\n",
       " 898,\n",
       " 1714,\n",
       " 7380,\n",
       " 30090,\n",
       " 547,\n",
       " 2982,\n",
       " 11,\n",
       " 290,\n",
       " 287,\n",
       " 465,\n",
       " 898,\n",
       " 3292,\n",
       " 8941,\n",
       " 257,\n",
       " 4636,\n",
       " 28582,\n",
       " 13,\n",
       " 18612,\n",
       " 35394,\n",
       " 30,\n",
       " 8673,\n",
       " 13,\n",
       " 1002,\n",
       " 340,\n",
       " 547,\n",
       " 11,\n",
       " 262,\n",
       " 15393,\n",
       " 286,\n",
       " 262,\n",
       " 5977,\n",
       " 373,\n",
       " 29178,\n",
       " 3474,\n",
       " 416,\n",
       " 1310,\n",
       " 40559,\n",
       " 11959,\n",
       " 1636,\n",
       " 11,\n",
       " 508,\n",
       " 11,\n",
       " 287,\n",
       " 477,\n",
       " 922,\n",
       " 4562,\n",
       " 11,\n",
       " 3181,\n",
       " 503,\n",
       " 287,\n",
       " 262,\n",
       " 37090,\n",
       " 257,\n",
       " 845,\n",
       " 22665,\n",
       " 366,\n",
       " 672,\n",
       " 270,\n",
       " 2838,\n",
       " 1,\n",
       " 319,\n",
       " 3619,\n",
       " 438,\n",
       " 505,\n",
       " 286,\n",
       " 883,\n",
       " 905,\n",
       " 88,\n",
       " 6685,\n",
       " 42070,\n",
       " 351,\n",
       " 4738,\n",
       " 6276,\n",
       " 871,\n",
       " 326,\n",
       " 314,\n",
       " 423,\n",
       " 2982,\n",
       " 357,\n",
       " 40,\n",
       " 1839,\n",
       " 470,\n",
       " 910,\n",
       " 416,\n",
       " 4150,\n",
       " 8,\n",
       " 3688,\n",
       " 284,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 12036,\n",
       " 13,\n",
       " 843,\n",
       " 523,\n",
       " 438,\n",
       " 14363,\n",
       " 10568,\n",
       " 852,\n",
       " 5729,\n",
       " 11331,\n",
       " 18893,\n",
       " 540,\n",
       " 438,\n",
       " 1169,\n",
       " 5114,\n",
       " 11835,\n",
       " 3724,\n",
       " 503,\n",
       " 11,\n",
       " 290,\n",
       " 11,\n",
       " 355,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 5469,\n",
       " 550,\n",
       " 11001,\n",
       " 11,\n",
       " 262,\n",
       " 2756,\n",
       " 286,\n",
       " 366,\n",
       " 38,\n",
       " 271,\n",
       " 10899,\n",
       " 82,\n",
       " 1,\n",
       " 1816,\n",
       " 510,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 1026,\n",
       " 373,\n",
       " 407,\n",
       " 10597,\n",
       " 1115,\n",
       " 812,\n",
       " 1568,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 1781,\n",
       " 286,\n",
       " 257,\n",
       " 1178,\n",
       " 2745,\n",
       " 6,\n",
       " 4686,\n",
       " 1359,\n",
       " 319,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 11,\n",
       " 340,\n",
       " 6451,\n",
       " 5091,\n",
       " 284,\n",
       " 502,\n",
       " 284,\n",
       " 4240,\n",
       " 1521,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 550,\n",
       " 1813,\n",
       " 510,\n",
       " 465,\n",
       " 12036,\n",
       " 13,\n",
       " 1550,\n",
       " 14580,\n",
       " 11,\n",
       " 340,\n",
       " 1107,\n",
       " 373,\n",
       " 257,\n",
       " 29850,\n",
       " 1917,\n",
       " 13,\n",
       " 1675,\n",
       " 24456,\n",
       " 465,\n",
       " 3656,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 1165,\n",
       " 2562,\n",
       " 438,\n",
       " 14363,\n",
       " 3148,\n",
       " 1650,\n",
       " 1010,\n",
       " 550,\n",
       " 587,\n",
       " 6699,\n",
       " 262,\n",
       " 1540,\n",
       " 558,\n",
       " 286,\n",
       " 2282,\n",
       " 326,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 550,\n",
       " 366,\n",
       " 7109,\n",
       " 14655,\n",
       " 683,\n",
       " 866,\n",
       " 526,\n",
       " 1114,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 438,\n",
       " 292,\n",
       " 884,\n",
       " 438,\n",
       " 18108,\n",
       " 407,\n",
       " 11196,\n",
       " 10597,\n",
       " 3016,\n",
       " 257,\n",
       " 614,\n",
       " 706,\n",
       " 3619,\n",
       " 338,\n",
       " 10568,\n",
       " 550,\n",
       " 587,\n",
       " 2077,\n",
       " 13,\n",
       " 632,\n",
       " 1244,\n",
       " 307,\n",
       " 326,\n",
       " 339,\n",
       " 550,\n",
       " 6405,\n",
       " 607,\n",
       " 438,\n",
       " 20777,\n",
       " 339,\n",
       " 8288,\n",
       " 465,\n",
       " 10152,\n",
       " 438,\n",
       " 13893,\n",
       " 339,\n",
       " 1422,\n",
       " 470,\n",
       " 765,\n",
       " 284,\n",
       " 467,\n",
       " 319,\n",
       " 12036,\n",
       " 26,\n",
       " 475,\n",
       " 340,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 1327,\n",
       " 284,\n",
       " 5879,\n",
       " 326,\n",
       " 339,\n",
       " 550,\n",
       " 1813,\n",
       " 510,\n",
       " 465,\n",
       " 12036,\n",
       " 780,\n",
       " 339,\n",
       " 550,\n",
       " 6405,\n",
       " 607,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5189,\n",
       " 1781,\n",
       " 11,\n",
       " 611,\n",
       " 673,\n",
       " 550,\n",
       " 407,\n",
       " 17901,\n",
       " 683,\n",
       " 866,\n",
       " 11,\n",
       " 673,\n",
       " 550,\n",
       " 8603,\n",
       " 11,\n",
       " 355,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 42397,\n",
       " 11,\n",
       " 4054,\n",
       " 284,\n",
       " 366,\n",
       " 26282,\n",
       " 683,\n",
       " 510,\n",
       " 1,\n",
       " 438,\n",
       " 7091,\n",
       " 550,\n",
       " 407,\n",
       " 2957,\n",
       " 683,\n",
       " 736,\n",
       " 284,\n",
       " 262,\n",
       " 1396,\n",
       " 417,\n",
       " 13,\n",
       " 1675,\n",
       " 1234,\n",
       " 262,\n",
       " 14093,\n",
       " 656,\n",
       " 465,\n",
       " 1021,\n",
       " 757,\n",
       " 438,\n",
       " 10919,\n",
       " 257,\n",
       " 410,\n",
       " 5040,\n",
       " 329,\n",
       " 257,\n",
       " 3656,\n",
       " 0,\n",
       " 887,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 4120,\n",
       " 284,\n",
       " 423,\n",
       " 595,\n",
       " 67,\n",
       " 1328,\n",
       " 340,\n",
       " 438,\n",
       " 392,\n",
       " 314,\n",
       " 2936,\n",
       " 340,\n",
       " 1244,\n",
       " 307,\n",
       " 3499,\n",
       " 284,\n",
       " 1064,\n",
       " 503,\n",
       " 1521,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 464,\n",
       " 748,\n",
       " 586,\n",
       " 652,\n",
       " 1204,\n",
       " 286,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 37733,\n",
       " 2346,\n",
       " 284,\n",
       " 884,\n",
       " 14177,\n",
       " 8233,\n",
       " 1020,\n",
       " 5768,\n",
       " 26,\n",
       " 290,\n",
       " 1719,\n",
       " 11,\n",
       " 319,\n",
       " 616,\n",
       " 835,\n",
       " 284,\n",
       " 22489,\n",
       " 40089,\n",
       " 11,\n",
       " 4978,\n",
       " 257,\n",
       " 19350,\n",
       " 286,\n",
       " 3619,\n",
       " 338,\n",
       " 3652,\n",
       " 436,\n",
       " 81,\n",
       " 5286,\n",
       " 8812,\n",
       " 2114,\n",
       " 1022,\n",
       " 262,\n",
       " 279,\n",
       " 1127,\n",
       " 11,\n",
       " 314,\n",
       " 550,\n",
       " 3589,\n",
       " 28068,\n",
       " 294,\n",
       " 1555,\n",
       " 262,\n",
       " 1306,\n",
       " 1110,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 40,\n",
       " 1043,\n",
       " 262,\n",
       " 3155,\n",
       " 379,\n",
       " 8887,\n",
       " 11061,\n",
       " 511,\n",
       " 18057,\n",
       " 12,\n",
       " 83,\n",
       " 6037,\n",
       " 26,\n",
       " 290,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 7062,\n",
       " 373,\n",
       " 523,\n",
       " 2429,\n",
       " 498,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 29543,\n",
       " 2745,\n",
       " 11,\n",
       " 314,\n",
       " 4752,\n",
       " 340,\n",
       " 6777,\n",
       " 13,\n",
       " 632,\n",
       " 373,\n",
       " 407,\n",
       " 326,\n",
       " 616,\n",
       " 2583,\n",
       " 408,\n",
       " 373,\n",
       " 366,\n",
       " 47914,\n",
       " 1298,\n",
       " 319,\n",
       " 326,\n",
       " 966,\n",
       " 314,\n",
       " 714,\n",
       " 423,\n",
       " 1813,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 262,\n",
       " 40830,\n",
       " 12719,\n",
       " 3874,\n",
       " 13,\n",
       " 632,\n",
       " 373,\n",
       " 655,\n",
       " 780,\n",
       " 673,\n",
       " 373,\n",
       " 4808,\n",
       " 1662,\n",
       " 62,\n",
       " 3499,\n",
       " 438,\n",
       " 361,\n",
       " 314,\n",
       " 743,\n",
       " 307,\n",
       " 41746,\n",
       " 12004,\n",
       " 262,\n",
       " 6473,\n",
       " 438,\n",
       " 5562,\n",
       " 314,\n",
       " 1043,\n",
       " 607,\n",
       " 523,\n",
       " 13,\n",
       " 1114,\n",
       " 3619,\n",
       " 11,\n",
       " 477,\n",
       " 465,\n",
       " 1204,\n",
       " 11,\n",
       " 550,\n",
       " 587,\n",
       " 11191,\n",
       " 416,\n",
       " 3499,\n",
       " 1466,\n",
       " 25,\n",
       " 484,\n",
       " 550,\n",
       " 26546,\n",
       " 1068,\n",
       " 465,\n",
       " 1242,\n",
       " 11,\n",
       " 340,\n",
       " 550,\n",
       " 587,\n",
       " 302,\n",
       " 1144,\n",
       " 287,\n",
       " 262,\n",
       " 3024,\n",
       " 12,\n",
       " 4803,\n",
       " 286,\n",
       " 511,\n",
       " 512,\n",
       " 1741,\n",
       " 13,\n",
       " 843,\n",
       " 340,\n",
       " 373,\n",
       " 4361,\n",
       " 5048,\n",
       " 425,\n",
       " 284,\n",
       " 3465,\n",
       " 644,\n",
       " 1245,\n",
       " 262,\n",
       " 366,\n",
       " 25124,\n",
       " 3101,\n",
       " 8137,\n",
       " 286,\n",
       " 16957,\n",
       " 1696,\n",
       " 414,\n",
       " 1,\n",
       " 357,\n",
       " 40,\n",
       " 9577,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 8,\n",
       " 373,\n",
       " 1719,\n",
       " 319,\n",
       " 683,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 40,\n",
       " 423,\n",
       " 4750,\n",
       " 326,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 373,\n",
       " 5527,\n",
       " 26,\n",
       " 290,\n",
       " 340,\n",
       " 373,\n",
       " 3393,\n",
       " 34953,\n",
       " 856,\n",
       " 326,\n",
       " 607,\n",
       " 5229,\n",
       " 373,\n",
       " 37895,\n",
       " 422,\n",
       " 428,\n",
       " 25179,\n",
       " 257,\n",
       " 19217,\n",
       " 475,\n",
       " 8904,\n",
       " 14676,\n",
       " 13,\n",
       " 632,\n",
       " 318,\n",
       " 11,\n",
       " 355,\n",
       " 257,\n",
       " 3896,\n",
       " 11,\n",
       " 262,\n",
       " 661,\n",
       " 508,\n",
       " 40987,\n",
       " 1637,\n",
       " 508,\n",
       " 651,\n",
       " 749,\n",
       " 503,\n",
       " 286,\n",
       " 340,\n",
       " 26,\n",
       " 290,\n",
       " 3619,\n",
       " 338,\n",
       " 19992,\n",
       " 31564,\n",
       " 286,\n",
       " 465,\n",
       " 3656,\n",
       " 338,\n",
       " 1263,\n",
       " 5236,\n",
       " 9343,\n",
       " 683,\n",
       " 11,\n",
       " 351,\n",
       " 281,\n",
       " 5585,\n",
       " 286,\n",
       " 2818,\n",
       " 922,\n",
       " 12,\n",
       " 49705,\n",
       " 11,\n",
       " 284,\n",
       " 21595,\n",
       " 1133,\n",
       " 340,\n",
       " 656,\n",
       " 5563,\n",
       " 286,\n",
       " 1242,\n",
       " 290,\n",
       " 13064,\n",
       " 13,\n",
       " 1675,\n",
       " 262,\n",
       " 6846,\n",
       " 11,\n",
       " 314,\n",
       " 1276,\n",
       " 751,\n",
       " 11,\n",
       " 339,\n",
       " 6150,\n",
       " 5365,\n",
       " 31655,\n",
       " 26,\n",
       " 475,\n",
       " 339,\n",
       " 373,\n",
       " 7067,\n",
       " 29396,\n",
       " 18443,\n",
       " 12271,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "972c97b3-f9df-4b33-9322-ff90cdf7f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Validation ratio\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fbcf2e0-7886-4c39-a1a1-09ca4024c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a322e259-f4f3-4199-a171-5e747de61881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9731cae6-cde9-4060-a3fa-266552e347be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Val loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f68811-8e7b-44a9-b9ea-45f9ec6387e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tokens: 4608\n",
      "Validation Tokens: 512\n",
      "All Tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training Tokens:\", train_tokens)\n",
    "print(\"Validation Tokens:\", val_tokens)\n",
    "print(\"All Tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4006f54d-b584-42cb-83a4-482fafd3ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7d51161-0192-43cb-a07c-3804dcdcf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        #Reduce the number of batches to match the total number of batches in the data loader\n",
    "        #If num_batches exceeds the number of batches in data_loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e181b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f28a9767-3147-47b4-b10e-cc2f5e3cb81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583690219456\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad(): #Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f56d4d53-71ce-42f1-a827-52d62d8ca9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6487])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perplexity\n",
    "torch.exp(torch.tensor([0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "245fab23-26e0-48fe-8bf2-25d2b38af340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e7526d8-f8b6-4840-87e4-a124cc0b50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37376831-7ea2-4e00-8207-bb1f8a772afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    #Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    #Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #Set model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() #Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() #Calculate loss gradients\n",
    "            optimizer.step() #Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            #Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        #Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "                model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \")) #Compact Print Format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e7413c2-9e00-4655-99c2-1b1f44b87fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f21d67e-fc53-4df3-8092-ed40fc039b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.926\n",
      "Ep 1 (Step 000005): Train loss 8.070, Val loss 8.341\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.624, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.599\n",
      "Every effort moves you, and,, and,, and,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.567, Val loss 6.483\n",
      "Ep 3 (Step 000025): Train loss 5.507, Val loss 6.408\n",
      "Every effort moves you, and, and of the of the of the, and, and. G. Gis, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 5.090, Val loss 6.324\n",
      "Ep 4 (Step 000035): Train loss 4.862, Val loss 6.334\n",
      "Every effort moves you.  \"I had been the picture-- the picture.               \"I was a the of the of the of the of the of the picture\"I had been the of\n",
      "Ep 5 (Step 000040): Train loss 4.262, Val loss 6.217\n",
      "Every effort moves you know the \"I had been--I to me--as of the donkey.     \"Oh, in the man of the picture--as Jack himself at the donkey--and it's the donkey--and it's it's\n",
      "Ep 6 (Step 000045): Train loss 3.872, Val loss 6.151\n",
      "Ep 6 (Step 000050): Train loss 3.334, Val loss 6.155\n",
      "Every effort moves you know the \"Oh, and.  \"Oh, and in a little: \"--I looked up, and in a little.       \"Oh, and he was, and down the room, and I\n",
      "Ep 7 (Step 000055): Train loss 3.329, Val loss 6.210\n",
      "Ep 7 (Step 000060): Train loss 2.583, Val loss 6.143\n",
      "Every effort moves you know the picture.  I glanced after him, and I was. I had been his pictures's an the fact, and I felt. I was his pictures--I had not the picture. I was, and down the room, I was\n",
      "Ep 8 (Step 000065): Train loss 2.089, Val loss 6.168\n",
      "Ep 8 (Step 000070): Train loss 1.759, Val loss 6.241\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, with the fact, the cigars you like.\"  He placed them at my elbow and as he said, and down the room, when I\n",
      "Ep 9 (Step 000075): Train loss 1.394, Val loss 6.229\n",
      "Ep 9 (Step 000080): Train loss 1.074, Val loss 6.274\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"Once, I was, in fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.806, Val loss 6.364\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "376dc539-89eb-4dda-95dc-f5e0ba9ca4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    #Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training Loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, label=\"Validation Loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) #Only show integer labels on x-axis\n",
    "\n",
    "    #Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() #Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #Invisible plo for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6531d33f-1917-48bb-a19c-81fcd23d7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "319e8f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "790f52e1-7058-436b-9851-a3011fb5369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54820fe9-f04e-4352-ba1e-b87569531172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3b316d2-a31f-4ede-ae76-bf3c24be7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v:k for k, v in vocab.items()}\n",
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe88d2ff-33b5-45c3-b86d-74eed24bb1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "        1.0120e-04, 3.5758e-01, 4.0122e-03])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cdd9bf4e-0003-4307-b3e9-a846c8dd3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id = torch.argmax(probas).item()\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d25e560d-29a3-438a-b937-f8c3d6f2e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab[next_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b3f66a6-a2b5-435b-90ef-e3c3a926703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60425ee2-6f2d-4ba6-bc09-91bffa2a6fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45ef9912-e58b-4a1b-a559-e0339813f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f2d1835-95da-4b82-b010-0c3044d50154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 X closer\n",
      "2 X every\n",
      "0 X effort\n",
      "544 X forward\n",
      "2 X inches\n",
      "1 X moves\n",
      "0 X pizza\n",
      "376 X toward\n",
      "4 X you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i,freq in enumerate(sampled_ids):\n",
    "            print(f\"{freq} X {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29c81129-6cdb-497d-990d-3897eba8c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a805a81c-18eb-42fe-ad3b-2dfae26f41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "#Calculate scaled probabilites\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "727fa861-0311-4ca1-ac06-5b17717840bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "        1.0120e-04, 3.5758e-01, 4.0122e-03])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_probas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75595164-151f-491d-a06e-564cc2ebdf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "        1.0120e-04, 3.5758e-01, 4.0122e-03])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3831b6ba-416a-4a3a-a901-0611ab110d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
       "        2.9718e-38, 9.0133e-03, 2.8514e-22])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_probas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5388d6f9-1dfd-4192-9623-6f6e86473551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_probas[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "712cdacb-dd65-4130-8f9d-fa5f3d932d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABM5klEQVR4nO3deVxU1f8/8Newg2wimyAKiiYUO0q4oUWCGmqkGWooIt8scYFwjUUgwDQR/YRiKu5rRlqaJvIRcc0dMxEDREhBcSVA1jm/P/xxP44DyH7v4Pv5eMzjw5y5d+Y185l8zz333HNEjDEGQgghhAiSHN8BCCGEEFI/KtSEEEKIgFGhJoQQQgSMCjUhhBAiYFSoCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECpsB3gPYmFotx7949aGhoQCQS8R2HEELIG4gxhn///RdGRkaQk2v4mPmNK9T37t2DiYkJ3zEIIYQQ5Ofno1u3bg1u88YVag0NDQAvPhxNTU2e0xBCCHkTFRcXw8TEhKtJDXnjCnVtd7empiYVakIIIbxqzClYGkxGCCGECBivhTotLQ0eHh4wMjKCSCTC/v37X7tPamoq7O3toaysDHNzc2zevLnNcxJCCCF84bVQl5aWwsbGBvHx8Y3a/vbt2xg1ahSGDRuGq1evYu7cuZg+fTp+//33Nk5KCCGE8IPXc9QjRozAiBEjGr19QkICzMzMsGLFCgCAhYUFTp06hZUrV8LNza2tYhJC2plYLEZlZSXfMQhpNkVFRcjLy7fKc8nUYLKzZ8/C1dVVos3NzQ1z586td5+KigpUVFRw94uLi9sqHiGkFVRWVuL27dsQi8V8RyGkRbS1tWFoaNjiOTtkqlAXFhbCwMBAos3AwADFxcV4/vw5VFVVpfaJiYlBeHh4e0UkhLQAYwwFBQWQl5eHiYnJayeCIESIGGMoKyvDgwcPAABdu3Zt0fPJVKFujkWLFiEwMJC7X3vtGiFEeKqrq1FWVgYjIyOoqanxHYeQZqs9cHzw4AH09fVb1A0uU4Xa0NAQ9+/fl2i7f/8+NDU16zyaBgBlZWUoKyu3RzxCGm+JVgOPPWu/HAJTU1MDAFBSUuI5CSEtV/tjs6qqqkWFWqb6lZydnZGSkiLRlpycDGdnZ54SEULaAs3DTzqC1voe81qoS0pKcPXqVVy9ehXAi8uvrl69iry8PAAvuq29vb257WfMmIGcnBzMnz8fN2/exJo1a7B3714EBATwEZ8QQghpc7wW6osXL8LOzg52dnYAgMDAQNjZ2SE0NBQAUFBQwBVtADAzM8OhQ4eQnJwMGxsbrFixAhs2bKBLswghhHRYvJ6jHjp0KBhj9T5e16xjQ4cOxZUrV9owFSFEaEwXHmrX18tdOqrR276uezMsLAxLlixpYSJhMTU1xdy5cxu8NFboZs+ejdOnT+P69euwsLDgenaFSKYGkxFCiNAUFBRwf+/ZswehoaHIzMzk2tTV1fmI1WSMMdTU1EBBof3KQmVlJa8DB6dNm4Y//vgD165d4y1DY8jUYDJCCBEaQ0ND7qalpQWRSCTRtnv3blhYWEBFRQV9+/bFmjVruH1zc3MhEomwd+9eDB48GKqqqujXrx9u3bqFCxcuwNHREerq6hgxYgSKioq4/aZOnYqxY8ciPDwcenp60NTUxIwZMyRmcxOLxYiJiYGZmRlUVVVhY2ODffv2cY+npqZCJBLh8OHDcHBwgLKyMk6dOoXs7GyMGTMGBgYGUFdXR79+/XDs2DFuv6FDh+LOnTsICAiASCTiehSWLFkCW1tbic8mLi4OpqamUrmjoqJgZGSEt956C8CLZYc/+eQTaGtrQ0dHB2PGjEFubm5r/N9Tr9WrV2PmzJno2bNnm75Oa6BCTQghbWTHjh0IDQ1FVFQUMjIyEB0djZCQEGzZskViu7CwMAQHB+Py5ctQUFDAxIkTMX/+fKxatQonT55EVlYWN3anVkpKCjIyMpCamopdu3YhKSlJYnKnmJgYbN26FQkJCfjrr78QEBCAyZMn48SJExLPs3DhQixduhQZGRmwtrZGSUkJRo4ciZSUFFy5cgXu7u7w8PDgxgslJSWhW7duiIiIQEFBgUSPQmOkpKQgMzMTycnJOHjwIKqqquDm5gYNDQ2cPHkSp0+fhrq6Otzd3RucRlZdXb3B24wZM5qUS8io65sQQtpIWFgYVqxYAU9PTwAvBsTeuHED69atw5QpU7jtgoKCuEGxc+bMgZeXF1JSUjBw4EAAgK+vr9SYHSUlJSQmJkJNTQ1vv/02IiIiMG/ePERGRqKqqgrR0dE4duwYd/lqz549cerUKaxbtw4uLi7c80REROCDDz7g7uvo6MDGxoa7HxkZiZ9//hm//PIL/P39oaOjA3l5eWhoaMDQ0LDJn0mnTp2wYcMGrst7+/btEIvF2LBhA3d0vmnTJmhrayM1NRXDhw+v83led05ZU1OzydmEigo1IYS0gdLSUmRnZ8PX1xd+fn5ce3V1NbS0JCe8sba25v6unSbZyspKoq12OspaNjY2ErO3OTs7o6SkBPn5+SgpKUFZWZlEAQZenBOuvcqmlqOjo8T9kpISLFmyBIcOHUJBQQGqq6vx/PlziStwWsLKykrivHR6ejqysrKgoaEhsV15eTmys7PrfR5zc/NWySMLqFATQkgbKCkpAQCsX78eTk5OEo+9OkuVoqIi93ftUeWrbU1ZpKT2tQ8dOgRjY2OJx16dqbFTp04S94OCgpCcnIzvvvsO5ubmUFVVxbhx4167mpmcnJzUVTxVVVVS2736eiUlJXBwcMCOHTukttXT06v39V43SG/y5MlISEhocBtZQYWaEELagIGBAYyMjJCTk4NJkya1+vOnp6dLLEZ07tw5qKurw8TEBDo6OlBWVkZeXp5EN3djnD59GlOnTsVHH30E4EUhfXVgl5KSEjfday09PT0UFhaCMcb92GjMJU/29vbYs2cP9PX1m9RdTV3fhBBCWiw8PByzZ8+GlpYW3N3dUVFRgYsXL+LJkycSiwU1R2VlJXx9fREcHIzc3FyEhYXB398fcnJy0NDQQFBQEAICAiAWizFo0CA8e/YMp0+fhqampsT58Vf17t0bSUlJ8PDwgEgkQkhIiNTRvKmpKdLS0vDpp59CWVkZurq6GDp0KIqKirBs2TKMGzcOR44cweHDh19bMCdNmoTly5djzJgxiIiIQLdu3XDnzh0kJSVh/vz56NatW537tbTrOysrCyUlJSgsLMTz58+5wm9paSm4ueZp1DchhLSR6dOnY8OGDdi0aROsrKzg4uKCzZs3w8zMrMXP/f7776N3794YMmQIJkyYgNGjR0tMrBIZGYmQkBDExMTAwsIC7u7uOHTo0GtfOzY2Fp07d8aAAQPg4eEBNzc32NvbS2wTERGB3Nxc9OrVi+uetrCwwJo1axAfHw8bGxucP38eQUFBr30fampqSEtLQ/fu3eHp6QkLCwv4+vqivLy8TY+Kp0+fDjs7O6xbtw63bt3iZsm8d+9em71mc4lYQ1ODdUDFxcXQ0tLCs2fPOlTXCJExtHpWncrLy3H79m2YmZlBRUWF7ziCNXXqVDx9+hT79+/nOwppQEPf56bUIjqiJoQQQgSMCjUhhBAiYDSYjBBCZExdCxaRjouOqAkhhBABo0JNCCGECBgVakIIIUTAqFATQgghAkaFmhBCCBEwKtSEEEKIgFGhJoSQFhCJRA3eXp7Ws6MwNTVFXFwc3zFaJC8vD6NGjYKamhr09fUxb948VFdXN7hPVFQUBgwYADU1NWhra7dPUNB11IQQWdDQlKtt8nqNn8a1oKCA+3vPnj0IDQ1FZmYm1/a65RiFgjGGmpoaKCi0X1morKzkZQGMmpoajBo1CoaGhjhz5gwKCgrg7e0NRUVFREdH17tfZWUlxo8fD2dnZ2zcuLHd8tIRNSGEtIChoSF309LSgkgkkmjbvXs3LCwsoKKigr59+2LNmjXcvrm5uRCJRNi7dy8GDx4MVVVV9OvXD7du3cKFCxfg6OgIdXV1jBgxAkVFRdx+U6dOxdixYxEeHg49PT1oampixowZEmtGi8VixMTEwMzMDKqqqrCxscG+ffu4x1NTUyESiXD48GE4ODhAWVkZp06dQnZ2NsaMGQMDAwOoq6ujX79+OHbsGLff0KFDcefOHQQEBHC9BgCwZMkS2NraSnw2cXFxMDU1lcodFRUFIyMjvPXWWwCA/Px8fPLJJ9DW1oaOjg7GjBkjtbRmazp69Chu3LiB7du3w9bWFiNGjEBkZCTi4+MbXHc7PDwcAQEBsLKyarNsdaFCTQghbWTHjh0IDQ1FVFQUMjIyEB0djZCQEGzZskViu7CwMAQHB+Py5ctQUFDAxIkTMX/+fKxatQonT55EVlYWQkNDJfZJSUlBRkYGUlNTsWvXLiQlJSE8PJx7PCYmBlu3bkVCQgL++usvBAQEYPLkyThx4oTE8yxcuBBLly5FRkYGrK2tUVJSgpEjRyIlJQVXrlyBu7s7PDw8kJeXBwBISkpCt27dEBERgYKCAokehcZISUlBZmYmkpOTcfDgQVRVVcHNzQ0aGho4efIkTp8+DXV1dbi7uzdYNNXV1Ru8zZgxo959z549CysrKxgYGHBtbm5uKC4uxl9//dWk99MeqOubEELaSFhYGFasWAFPT08AgJmZGW7cuIF169ZJrAkdFBQENzc3AMCcOXPg5eWFlJQUDBw4EADg6+srNW2okpISEhMToaamhrfffhsRERGYN28eIiMjUVVVhejoaBw7dgzOzs4AgJ49e+LUqVNYt24dXFxcuOeJiIjABx98wN3X0dGBjY0Ndz8yMhI///wzfvnlF/j7+0NHRwfy8vLQ0NCAoaFhkz+TTp06YcOGDVyX9/bt2yEWi7Fhwwbu6HzTpk3Q1tZGamoqhg8fXufz1K4fXZ+GVqQqLCyUKNIAuPuFhYWNfSvthgo1IYS0gdLSUmRnZ8PX1xd+fn5ce3V1NbS0JM+5W1tbc3/XFoyXu1cNDAzw4MEDiX1sbGygpqbG3Xd2dkZJSQny8/NRUlKCsrIyiQIMvDjHamdnJ9Hm6Ogocb+kpARLlizBoUOHUFBQgOrqajx//pw7om4pKysrifPS6enpyMrKgoaGhsR25eXlyM7Orvd5zM3NWyWPLKBCTQghbaCkpAQAsH79ejg5OUk8Ji8vL3FfUVGR+7v2qPLVNrFY3OTXPnToEIyNjSUeU1ZWlrjfqVMniftBQUFITk7Gd999B3Nzc6iqqmLcuHENdkMDgJycHBhjEm1VVVVS2736eiUlJXBwcMCOHTukttXT06v39V43SG/y5MlISEio8zFDQ0OcP39eou3+/fvcY0JDhZoQQtqAgYEBjIyMkJOTg0mTJrX686enp+P58+dQVVUFAJw7dw7q6uowMTGBjo4OlJWVkZeXJ9HN3RinT5/G1KlT8dFHHwF4UUhfHdilpKSEmpoaiTY9PT0UFhaCMcb92Hhd9zQA2NvbY8+ePdDX12+wu/pVLen6dnZ2RlRUFB48eAB9fX0AQHJyMjQ1NWFpadnoDO2FCjUhhLSR8PBwzJ49G1paWnB3d0dFRQUuXryIJ0+eIDAwsEXPXVlZCV9fXwQHByM3NxdhYWHw9/eHnJwcNDQ0EBQUhICAAIjFYgwaNAjPnj3D6dOnoampKXF+/FW9e/dGUlISPDw8IBKJEBISInU0b2pqirS0NHz66adQVlaGrq4uhg4diqKiIixbtgzjxo3DkSNHcPjw4dcW30mTJmH58uUYM2YMIiIi0K1bN9y5cwdJSUmYP38+unXrVud+Len6Hj58OCwtLfHZZ59h2bJlKCwsRHBwMGbOnMn1OJw/fx7e3t5ISUnheiXy8vLw+PFj5OXloaamhvuxYG5u3qaX4fE+6js+Ph6mpqZQUVGBk5OTVHfEq+Li4vDWW29BVVUVJiYmCAgIQHl5eTulJYSQxps+fTo2bNiATZs2wcrKCi4uLti8eTPMzMxa/Nzvv/8+evfujSFDhmDChAkYPXq0xOQqkZGRCAkJQUxMDCwsLODu7o5Dhw699rVjY2PRuXNnDBgwAB4eHnBzc4O9vb3ENhEREcjNzUWvXr247mkLCwusWbMG8fHxsLGxwfnz5xEUFPTa96Gmpoa0tDR0794dnp6esLCwgK+vL8rLy5t0hN0U8vLyOHjwIOTl5eHs7IzJkyfD29sbERER3DZlZWXIzMyU6L4PDQ2FnZ0dwsLCUFJSAjs7O9jZ2eHixYttkrOWiL16UqEd7dmzB97e3khISICTkxPi4uLw448/IjMzk+uOeNnOnTsxbdo0JCYmYsCAAbh16xamTp2KTz/9FLGxsY16zeLiYmhpaeHZs2dt9iUg5LUamsCjCZNtdDTl5eW4ffs2zMzMoKKiwnccwZo6dSqePn2K/fv38x2FNKCh73NTahGvR9SxsbHw8/ODj48PLC0tkZCQADU1NSQmJta5/ZkzZzBw4EBMnDgRpqamGD58OLy8vF57FE4IIYTIKt4KdWVlJS5dugRXV9f/hZGTg6urK86ePVvnPgMGDMClS5e4wpyTk4PffvsNI0eObJfMhBBCSHvjbTDZw4cPUVNTU+dF5zdv3qxzn4kTJ+Lhw4cYNGgQGGOorq7GjBkzsHjx4npfp6KiAhUVFdz94uLi1nkDhBDCk1cnPyEdG++DyZoiNTUV0dHRWLNmDS5fvoykpCQcOnQIkZGR9e4TExMDLS0t7mZiYtKOiQkhhJCW4e2IWldXF/Ly8txF5rXu379f7wXnISEh+OyzzzB9+nQAL2a4KS0txf/93//h66+/hpyc9O+ORYsWSVwGUVxcTMWaEEKIzODtiFpJSQkODg5ISUnh2sRiMVJSUri5aV9VVlYmVYxrZ/ipb/C6srIyNDU1JW6EEEKIrOB1wpPAwEBMmTIFjo6O6N+/P+Li4lBaWgofHx8AgLe3N4yNjRETEwMA8PDwQGxsLOzs7ODk5ISsrCyEhITAw8NDako+QgghpCPgtVBPmDABRUVFCA0NRWFhIWxtbXHkyBFugFleXp7EEXRwcDBEIhGCg4Nx9+5d6OnpwcPDA1FRUXy9BUIIIaRN8TrhCR9owhMiCDThSZ1owhPSkXSICU8IIYQQ0jAq1IQQ0gIikajB28vzb3cUpqamiIuL4ztGi9T1/9Xu3bv5jlUnWj2LECJ4Vlus2vX1/pzyZ6O3LSgo4P7es2cPQkNDkZmZybW15apKrYkxhpqaGigotF9ZqKyshJKSUru93qs2bdoEd3d37r62tjZvWRpCR9SEENIChoaG3E1LSwsikUiibffu3bCwsICKigr69u2LNWvWcPvm5uZCJBJh7969GDx4MFRVVdGvXz/cunULFy5cgKOjI9TV1TFixAgUFRVx+02dOhVjx45FeHg49PT0oKmpiRkzZqCyspLbRiwWIyYmBmZmZlBVVYWNjQ327dvHPZ6amgqRSITDhw/DwcEBysrKOHXqFLKzszFmzBgYGBhAXV0d/fr1w7Fjx7j9hg4dijt37iAgIIA7EgWAJUuWwNbWVuKziYuLg6mpqVTuqKgoGBkZ4a233gIA5Ofn45NPPoG2tjZ0dHQwZswYqTWw24K2trbE/1dCHRdBhZoQQtrIjh07EBoaiqioKGRkZCA6OhohISHYsmWLxHZhYWEIDg7G5cuXoaCggIkTJ2L+/PlYtWoVTp48iaysLISGhkrsk5KSgoyMDKSmpmLXrl1ISkpCeHg493hMTAy2bt2KhIQE/PXXXwgICMDkyZNx4sQJiedZuHAhli5dioyMDFhbW6OkpAQjR45ESkoKrly5And3d3h4eCAvLw8AkJSUhG7duiEiIgIFBQUSPQqNkZKSgszMTCQnJ+PgwYOoqqqCm5sbNDQ0cPLkSZw+fRrq6upwd3eX+OHxKnV19QZvM2bMeG2WmTNnQldXF/3790diYmK983Hwjbq+CSGkjYSFhWHFihXw9PQEAJiZmeHGjRtYt24dpkyZwm0XFBQENzc3AMCcOXPg5eWFlJQUDBw4EADg6+srNb+3kpISEhMToaamhrfffhsRERGYN28eIiMjUVVVhejoaBw7doybQKpnz544deoU1q1bBxcXF+55IiIi8MEHH3D3dXR0YGNjw92PjIzEzz//jF9++QX+/v7Q0dGBvLw8NDQ06p1FsiGdOnXChg0buC7v7du3QywWY8OGDdzR+aZNm6CtrY3U1FQMHz68zue5evVqg6/zupHUEREReO+996CmpoajR4/iyy+/RElJCWbPnt3k99TWqFATQkgbKC0tRXZ2Nnx9feHn58e1V1dXQ0tL8vI8a2tr7u/aeSSsrKwk2h48eCCxj42NDdTU1Lj7zs7OKCkpQX5+PkpKSlBWViZRgIEX54Tt7Owk2hwdHSXul5SUYMmSJTh06BAKCgpQXV2N58+fc0fULWVlZSVxXjo9PR1ZWVnQ0NCQ2K68vBzZ2dn1Po+5uXmLcoSEhHB/29nZobS0FMuXL6dCTQghb4qSkhIAwPr16+Hk5CTx2KszKSoqKnJ/1x5VvtomFoub/NqHDh2CsbGxxGPKysoS9zt16iRxPygoCMnJyfjuu+9gbm4OVVVVjBs3rsFuaODFMsWvdh1XVVVJbffq65WUlMDBwQE7duyQ2lZPT6/e13vdIL3JkycjISGhwW1e5uTkhMjISFRUVEh9RnyjQk0IIW3AwMAARkZGyMnJwaRJk1r9+dPT0/H8+XOoqqoCAM6dOwd1dXWYmJhAR0cHysrKyMvLk+jmbozTp09j6tSp+OijjwC8KKSvDuxSUlJCTU2NRJuenh4KCwvBGON+bLyuexoA7O3tsWfPHujr6zdpEqqWdn3X9XydO3cWXJEGqFATQkibCQ8Px+zZs6GlpQV3d3dUVFTg4sWLePLkicSqfs1RWVkJX19fBAcHIzc3F2FhYfD394ecnBw0NDQQFBSEgIAAiMViDBo0CM+ePcPp06ehqakpcX78Vb1790ZSUhI8PDwgEokQEhIidTRvamqKtLQ0fPrpp1BWVoauri6GDh2KoqIiLFu2DOPGjcORI0dw+PDh1xbMSZMmYfny5RgzZgwiIiLQrVs33LlzB0lJSZg/fz66detW534t6fr+9ddfcf/+fbz77rtQUVFBcnIyoqOjERQU1OznbEs06psQQtrI9OnTsWHDBmzatAlWVlZwcXHB5s2bYWZm1uLnfv/999G7d28MGTIEEyZMwOjRoyUmV4mMjERISAhiYmJgYWEBd3d3HDp06LWvHRsbi86dO2PAgAHw8PCAm5sb7O3tJbaJiIhAbm4uevXqxXVPW1hYYM2aNYiPj4eNjQ3Onz/fqMKnpqaGtLQ0dO/eHZ6enrCwsICvry/Ky8vbbJpnRUVFxMfHw9nZGba2tli3bh1iY2MRFhbWJq/XUjTXNyF8oLm+60RzfTfO1KlT8fTpU+zfv5/vKKQBNNc3IYQQ8gagQk0IIYQIGA0mI4QQGfPq5CekY2vWEfXx48dbOwchhBBC6tCsQu3u7o5evXrhm2++QX5+fmtnIoQQQsj/16xCfffuXfj7+2Pfvn3o2bMn3NzcsHfv3tfOXEMIIY3xhl2MQjqo1voeN6tQ6+rqIiAgAFevXsUff/yBPn364Msvv4SRkRFmz56N9PT0VglHCHmz1E6tST/6SUdQVlYGQHI62OZo8WAye3t7GBoaokuXLli6dCkSExOxZs0aODs7IyEhAW+//XZLX4IQ8oZQUFCAmpoaioqKoKioCDk5ujCFyB7GGMrKyvDgwQNoa2tLze3eVM0u1FVVVThw4AASExORnJwMR0dHfP/99/Dy8kJRURGCg4Mxfvx43Lhxo0UBCSFvDpFIhK5du+L27du4c+cO33EIaRFtbe1mLQX6qmYV6lmzZmHXrl1gjOGzzz7DsmXL8M4773CPd+rUCd999x2MjIxaHJAQ8mZRUlJC7969qfubyDRFRcUWH0nXalahvnHjBv7zn//A09Oz3pVGdHV16TIuQkizyMnJ0RSihPx/zToBFBYWhvHjx0sV6erqaqSlpQF4ca6pqcurEUIIIURSswr1sGHD8PjxY6n2Z8+eYdiwYS0ORQghhJAXmlWoX14Y/GWPHj1Cp06dWhyKEEIIIS806Ry1p6cngBcjM6dOnSrR9V1TU4Nr165hwIABrZuQEEIIeYM1qVBrab1YQ5cxBg0NDaiqqnKPKSkp4d1334Wfn1/rJiSEEELeYE0q1Js2bQIAmJqaIigoiLq5CSGEkDbW7FHfrVWk4+PjYWpqChUVFTg5OeH8+fMNbv/06VPMnDkTXbt2hbKyMvr06YPffvutVbIQQgghQtPoI2p7e3ukpKSgc+fOsLOzq3MwWa3Lly836jn37NmDwMBAJCQkwMnJCXFxcXBzc0NmZib09fWltq+srMQHH3wAfX197Nu3D8bGxrhz5w60tbUb+zYIIYQQmdLoQj1mzBhu8NjYsWNb5cVjY2Ph5+cHHx8fAEBCQgIOHTqExMRELFy4UGr7xMREPH78GGfOnOEmOTc1NW2VLIQQQogQiRhP68lVVlZCTU0N+/btkyj8U6ZMwdOnT3HgwAGpfUaOHAkdHR2oqanhwIED0NPTw8SJE7FgwYJ6p2qrqKhARUUFd7+4uBgmJiZ49uwZNDU1W/19EdIoS7QaeOxZ++UghPCiuLgYWlpajapFvC1N8/DhQ9TU1MDAwECi3cDAAIWFhXXuk5OTg3379qGmpga//fYbQkJCsGLFCnzzzTf1vk5MTAy0tLS4m4mJSau+D0IIIaQtNbrru3Pnzg2el35ZXbOWtQaxWAx9fX388MMPkJeXh4ODA+7evYvly5cjLCyszn0WLVqEwMBA7n7tETUhhBAiCxpdqOPi4lr1hXV1dSEvL4/79+9LtN+/f7/eZcG6du0qtSKJhYUFCgsLUVlZCSUlJal9lJWV6104hBBCCBG6RhfqKVOmtOoLKykpwcHBASkpKdw5arFYjJSUFPj7+9e5z8CBA7Fz506IxWJuQflbt26ha9eudRZpQgghRNY1+hx1cXGxxN8N3RorMDAQ69evx5YtW5CRkYEvvvgCpaWl3Chwb29vLFq0iNv+iy++wOPHjzFnzhzcunULhw4dQnR0NGbOnNno1ySEEEJkSZPOURcUFEBfXx/a2tp1nq+uXayjpqamUc85YcIEFBUVITQ0FIWFhbC1tcWRI0e4AWZ5eXnckTMAmJiY4Pfff0dAQACsra1hbGyMOXPmYMGCBY19G4QQQohMafTlWSdOnMDAgQOhoKCAEydONLitkNehbsqQeEJawnThoXofy1WZWP+OdHkWIR1eU2pRo4+oXy6+Qi7EhBBCSEfSpEU5XvbkyRNs3LgRGRkZAABLS0v4+PhAR0en1cIRQgghb7pmTXiSlpYGU1NTrF69Gk+ePMGTJ0+wevVqmJmZIS0trbUzEkIIIW+sZh1Rz5w5ExMmTMDatWu5a5pramrw5ZdfYubMmfjzzz9bNSQhhBDypmrWEXVWVha++uoriYlH5OXlERgYiKysrFYLRwghhLzpmlWo7e3tuXPTL8vIyICNjU2LQxFCCCHkhUZ3fV+7do37e/bs2ZgzZw6ysrLw7rvvAgDOnTuH+Ph4LF26tPVTEkIIIW+oRl9HLScnB5FIhNdt3pQJT/hA11GT9kLXURNC6tMm11Hfvn27xcEIIYQQ0jSNLtQ9evRoyxyEEEIIqUOzJzwBgBs3biAvLw+VlZUS7aNHj25RKEIIIYS80KxCnZOTg48++gh//vmnxHnr2oU6hHyOmhBCCJElzbo8a86cOTAzM8ODBw+gpqaGv/76C2lpaXB0dERqamorRySEEELeXM06oj579iz++9//QldXF3JycpCTk8OgQYMQExOD2bNn48qVK62dkxBCCHkjNeuIuqamBhoaGgAAXV1d3Lt3D8CLAWeZmZmtl44QQgh5wzXriPqdd95Beno6zMzM4OTkhGXLlkFJSQk//PADevbs2doZCSGEkDdWswp1cHAwSktLAQARERH48MMPMXjwYHTp0gV79uxp1YCEEELIm6xZhdrNzY3729zcHDdv3sTjx4/RuXNnbuQ3IYQQQlquRddRA0B+fj4AwMTEpMVhCCGEECKpWYPJqqurERISAi0tLZiamsLU1BRaWloIDg5GVVVVa2ckhBBC3ljNOqKeNWsWkpKSsGzZMjg7OwN4ccnWkiVL8OjRI6xdu7ZVQxJCCCFvqmYV6p07d2L37t0YMWIE12ZtbQ0TExN4eXlRoSaEEEJaSbO6vpWVlWFqairVbmZmBiUlpZZmIoQQQsj/16xC7e/vj8jISFRUVHBtFRUViIqKgr+/f6uFI4QQQt50je769vT0lLh/7NgxdOvWDTY2NgCA9PR0VFZW4v3332/dhIQQQsgbrNGFWktLS+L+xx9/LHGfLs8ihBBCWl+jC/WmTZvaMgchhBBC6tCiCU+Kioq4RTjeeust6OnptUooQgghhLzQrMFkpaWlmDZtGrp27YohQ4ZgyJAhMDIygq+vL8rKylo7IyGEEPLGalahDgwMxIkTJ/Drr7/i6dOnePr0KQ4cOIATJ07gq6++avLzxcfHw9TUFCoqKnBycsL58+cbtd/u3bshEokwduzYJr8mIYQQIguaVah/+uknbNy4ESNGjICmpiY0NTUxcuRIrF+/Hvv27WvSc+3ZsweBgYEICwvD5cuXYWNjAzc3Nzx48KDB/XJzcxEUFITBgwc35y0QQgghMqFZhbqsrAwGBgZS7fr6+k3u+o6NjYWfnx98fHxgaWmJhIQEqKmpITExsd59ampqMGnSJISHh9P614QQQjq0ZhVqZ2dnhIWFoby8nGt7/vw5wsPDubm/G6OyshKXLl2Cq6vr/wLJycHV1RVnz56td7+IiAjo6+vD19f3ta9RUVGB4uJiiRshhBAiK5o16jsuLg7u7u5SE56oqKjg999/b/TzPHz4EDU1NVJH5wYGBrh582ad+5w6dQobN27E1atXG/UaMTExCA8Pb3QmQgghREiaVaitrKzw999/Y8eOHVxB9fLywqRJk6CqqtqqAV/277//4rPPPsP69euhq6vbqH0WLVqEwMBA7n5xcTFNzkIIIURmNLlQV1VVoW/fvjh48CD8/Pxa9OK6urqQl5fH/fv3Jdrv378PQ0NDqe2zs7ORm5sLDw8Prk0sFgMAFBQUkJmZiV69eknso6ysDGVl5RblJIQQQvjS5HPUioqKEuemW0JJSQkODg5ISUnh2sRiMVJSUuo81923b1/8+eefuHr1KncbPXo0hg0bhqtXr9KRMiGEkA6nWV3fM2fOxLfffosNGzZAQaFFk5shMDAQU6ZMgaOjI/r374+4uDiUlpbCx8cHAODt7Q1jY2PExMRARUUF77zzjsT+2traACDVTgghhHQEzaqyFy5cQEpKCo4ePQorKyt06tRJ4vGkpKRGP9eECRNQVFSE0NBQFBYWwtbWFkeOHOEGmOXl5UFOrlmD0wkhhBCZ16xCra2tLbV6Vkv4+/vXu451ampqg/tu3ry51XIQQgghQtOkQi0Wi7F8+XLcunULlZWVeO+997BkyZI2HelNCCGEvMma1KccFRWFxYsXQ11dHcbGxli9ejVmzpzZVtkIIYSQN16Tjqi3bt2KNWvW4PPPPwcAHDt2DKNGjcKGDRvoPDIhhHRwpgsP1dmeu3RUOyd5szSpuubl5WHkyJHcfVdXV4hEIty7d6/VgxFCCCGkiYW6uroaKioqEm2Kioqoqqpq1VCEEEIIeaFJXd+MMUydOlVipq/y8nLMmDFD4hKtplyeRQghhJD6NalQT5kyRapt8uTJrRaGEEIIIZKaVKg3bdrUVjkIIYQQUgcaqk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBIwKNSGEECJgVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEEEIEjAo1IYQQImBUqAkhhBABo0JNCCGECJgC3wEIIZKstljV+9ifU/5sxySEECGgI2pCCCFEwKhQE0IIIQImiEIdHx8PU1NTqKiowMnJCefPn6932/Xr12Pw4MHo3LkzOnfuDFdX1wa3J4QQQmQZ7+eo9+zZg8DAQCQkJMDJyQlxcXFwc3NDZmYm9PX1pbZPTU2Fl5cXBgwYABUVFXz77bcYPnw4/vrrLxgbG/PwDgghhNSHxly0HO9H1LGxsfDz84OPjw8sLS2RkJAANTU1JCYm1rn9jh078OWXX8LW1hZ9+/bFhg0bIBaLkZKS0s7JCSGEkLbHa6GurKzEpUuX4OrqyrXJycnB1dUVZ8+ebdRzlJWVoaqqCjo6Om0VkxBCCOENr13fDx8+RE1NDQwMDCTaDQwMcPPmzUY9x4IFC2BkZCRR7F9WUVGBiooK7n5xcXHzAxNCCCHtjPeu75ZYunQpdu/ejZ9//hkqKip1bhMTEwMtLS3uZmJi0s4pCSGEkObjtVDr6upCXl4e9+/fl2i/f/8+DA0NG9z3u+++w9KlS3H06FFYW1vXu92iRYvw7Nkz7pafn98q2QkhhJD2wGuhVlJSgoODg8RAsNqBYc7OzvXut2zZMkRGRuLIkSNwdHRs8DWUlZWhqakpcSOEEEJkBe+XZwUGBmLKlClwdHRE//79ERcXh9LSUvj4+AAAvL29YWxsjJiYGADAt99+i9DQUOzcuROmpqYoLCwEAKirq0NdXZ2390EIIYS0Bd4L9YQJE1BUVITQ0FAUFhbC1tYWR44c4QaY5eXlQU7ufwf+a9euRWVlJcaNGyfxPGFhYViyZEl7RieEEELaHO+FGgD8/f3h7+9f52OpqakS93Nzc9s+ECGEECIQMj3qmxBCCOnoqFATQgghAkaFmhBCCBEwQZyjfhPRRPWEEEIag46oCSGEEAGjQk0IIYQIGBVqQgghRMCoUBNCCCECRoWaEEIIETAq1IQQQoiAUaEmhBBCBIwKNSGEECJgVKgJIYQQAaNCTQghhAgYFWpCCCFEwKhQE0IIIQJGi3IQQlqMFpkhHYnQvs90RE0IIYQIGBVqQgghRMCo65s0mtC6gwgh5E1AR9SEEEKIgFGhJoQQQgSMur5byHThoXofy106qh2TEEII6YjoiJoQQggRMCrUhBBCiIBR1zfp0GikOqmPLH43ZDEzaTk6oiaEEEIEjAo1IYQQImBUqAkhhBABE0Shjo+Ph6mpKVRUVODk5ITz5883uP2PP/6Ivn37QkVFBVZWVvjtt9/aKSkhhBDSvngv1Hv27EFgYCDCwsJw+fJl2NjYwM3NDQ8ePKhz+zNnzsDLywu+vr64cuUKxo4di7Fjx+L69evtnJwQQghpe7wX6tjYWPj5+cHHxweWlpZISEiAmpoaEhMT69x+1apVcHd3x7x582BhYYHIyEjY29vj+++/b+fkhBBCSNvj9fKsyspKXLp0CYsWLeLa5OTk4OrqirNnz9a5z9mzZxEYGCjR5ubmhv3797dlVEIIIfVZolX/Y2bd2y9HB8VroX748CFqampgYGAg0W5gYICbN2/WuU9hYWGd2xcWFta5fUVFBSoqKrj7z549AwAUFxe3JDpHXFFW72MNvUbN85pm7dca3gn7vd7Hroe71fsYn5mbi8/MDX43RKzex/j+nOv7ftB3g398Z67vO03f56arfR7G6v/sOIxHd+/eZQDYmTNnJNrnzZvH+vfvX+c+ioqKbOfOnRJt8fHxTF9fv87tw8LCGAC60Y1udKMb3QR3y8/Pf22t5PWIWldXF/Ly8rh//75E+/3792FoaFjnPoaGhk3aftGiRRJd5WKxGI8fP0aXLl0gEola+A4kFRcXw8TEBPn5+dDU1GzV524rlLl9UOb2QZnbB2VuOcYY/v33XxgZGb12W14LtZKSEhwcHJCSkoKxY8cCeFFIU1JS4O/vX+c+zs7OSElJwdy5c7m25ORkODs717m9srIylJWVJdq0tbVbI369NDU1BfFFaArK3D4oc/ugzO2DMreMlpZWo7bjfa7vwMBATJkyBY6Ojujfvz/i4uJQWloKHx8fAIC3tzeMjY0RExMDAJgzZw5cXFywYsUKjBo1Crt378bFixfxww8/8Pk2CCGEkDbBe6GeMGECioqKEBoaisLCQtja2uLIkSPcgLG8vDzIyf3vKrIBAwZg586dCA4OxuLFi9G7d2/s378f77zzDl9vgRBCCGkzvBdqAPD396+3qzs1NVWqbfz48Rg/fnwbp2o6ZWVlhIWFSXW1Cxllbh+UuX1Q5vZBmduXiLHGjA0nhBBCCB94n5mMEEIIIfWjQk0IIYQIGBVqQgghRMCoUBNCCCECRoW6maqrq7F161apWdIIIYSQ1kSjvltATU0NGRkZ6NGjB99RGm3KlCnw9fXFkCFD+I7SJD179sSFCxfQpUsXifanT5/C3t4eOTk5PCX7n19++aXR244ePboNk7zZampq8Oeff6JHjx7o3Lkz33FkVlMWnxDKTF+vSktLa/BxWfl3UBDXUcuq/v374+rVqzJVqJ89ewZXV1f06NEDPj4+mDJlCoyNjfmO9Vq5ubmoqZFe0aaiogJ3797lIZG02mlwa4lEIomVcV6eW76u9yIEW7Zsga6uLkaNGgUAmD9/Pn744QdYWlpi165dgvyuz507F1ZWVvD19UVNTQ1cXFxw5swZqKmp4eDBgxg6dCjfEWWStrZ2o9dDEOr3ua7/72Xhv8NXUaFugS+//BKBgYHIz8+Hg4MDOnXqJPG4tbU1T8nqt3//fhQVFWHbtm3YsmULwsLC4OrqCl9fX4wZMwaKiop8R5Tw8lHq77//LjE3bk1NDVJSUmBqaspDMmlisZj7+9ixY1iwYAGio6O5eejPnj2L4OBgREdH8xXxtaKjo7F27VoAL/LGx8dj5cqVOHjwIAICApCUlMRzQmn79u3D5MmTAQC//vorbt++jZs3b2Lbtm34+uuvcfr0aZ4T1m3fvn3Yu3cv8vLyUFlZKfHY5cuXeUr1P8ePH+f+zs3NxcKFCzF16lSJ7/OWLVu46Z2F6MmTJxL3q6qqcOXKFYSEhCAqKoqnVM3w2vW1SL1EIpHUTU5OjvtfWXDp0iXm7+/PVFRUmK6uLps7dy67desW37E4dX3GtTclJSXWp08f9uuvv/IdU8rbb7/NTp48KdWelpbG+vbty0OixlFVVWV37txhjDE2f/589tlnnzHGGLt+/TrT1dXlM1q9lJWVuaUC/fz82Jw5cxhjjOXk5DANDQ0ek9Vv1apVTF1dnfn7+zMlJSX2+eefM1dXV6alpcUWL17Mdzwp7733ntTywowxtmPHDubi4tL+gVooNTWV2dvb8x2j0WgwWQvcvn1b6paTk8P9r9AVFBQgOTkZycnJkJeXx8iRI/Hnn3/C0tISK1eu5DsegBdHqWKxGD169EBRURF3XywWo6KiApmZmfjwww/5jiklOzu7zlXatLS0kJub2+55GktdXR2PHj0CABw9ehQffPABAEBFRQXPnz/nM1q9DAwMcOPGDdTU1ODIkSNc5rKyMsjLy/Ocrm5r1qzBDz/8gP/85z9QUlLC/PnzkZycjNmzZ+PZs2d8x5Ny9uxZODo6SrU7Ojri/PnzPCRqGQMDA2RmZvIdo/H4/qVA2ldlZSXbt28fGzVqFFNUVGQODg5s7dq17NmzZ9w2SUlJTFtbm8eUkiorK9l7770nqCP91xk8eDD74IMPWGFhIddWWFjIhg8fzoYMGcJjsoZNnDiR2dvbM19fX6ampsYePnzIGGPswIED7O233+Y5Xd3CwsKYlpYW69u3L+vevTsrLy9njDG2ceNG9u677/Kcrm6qqqosNzeXMcaYnp4eu3r1KmOMsVu3bjEdHR0+o9WpT58+bN68eVLt8+bNY3369OEhUeOkp6dL3K5evcoOHz7MXFxc2MCBA/mO12h0jrqFtm3bhoSEBNy+fRtnz55Fjx49EBcXBzMzM4wZM4bveFK6du0KsVgMLy8vnD9/Hra2tlLbDBs2rM3X7G4KRUVFXLt2je8YTbJx40Z4enqie/fuMDExAQDk5+dzq70JVXx8PIKDg5Gfn4+ffvqJG2V/6dIleHl58ZyubkuWLME777yD/Px8jB8/nlt0QV5eHgsXLuQ5Xd0MDQ3x+PFj9OjRA927d8e5c+dgY2OD27dvSwxAFIqVK1fi448/xuHDh+Hk5AQAOH/+PP7++2/89NNPPKern62trdSgTgB49913kZiYyFOqpqPLs1pg7dq1CA0Nxdy5cxEVFYXr16+jZ8+e2Lx5M7Zs2SIxGEMotm3bhvHjx0NFRYXvKE0SEBAAZWVlLF26lO8ojcYYQ3JyMm7evAkAsLCwgKura6NH0pKmKy8vl4nv9vTp02FiYoKwsDDEx8dj3rx5GDhwIC5evAhPT09s3LiR74hS/vnnH6xduxYZGRkAXnyfZ8yYwf0QFaI7d+5I3JeTk4Oenp5MfEdeRoW6BSwtLREdHY2xY8dCQ0MD6enp6NmzJ65fv46hQ4fi4cOHfEeUUFVVBVVVVVy9elXm1u+eNWsWtm7dit69e9c5wj42NpanZNJk+XMGgJMnT2LdunXIycnBjz/+CGNjY2zbtg1mZmYYNGgQ3/Gk1NTUIDo6GgkJCbh//z5u3bqFnj17IiQkBKampvD19eU7opTacRYKCi86NXfv3o0zZ86gd+/e+Pzzz6GkpMRzwv+pqqqCu7s7EhIS0Lt3b77jvJFoMFkL3L59G3Z2dlLtysrKKC0t5SFRwxQVFdG9e3eZuXbwZdevX4e9vT00NDRw69YtXLlyhbtdvXqV73gSZPlz/umnn+Dm5gZVVVVcvnwZFRUVAF5cfy/Uy8qioqKwefNmLFu2TKLAvfPOO9iwYQOPyeonJyfHFWkA+PTTT7F69WrMmjVLUEUakM1TTy87ceIEPDw8YG5uDnNzc4wePRonT57kO1bT8Hh+XOZZWFiw/fv3M8YYU1dXZ9nZ2YwxxlavXs3s7Oz4jFavDRs2sJEjR7JHjx7xHaVDk9XP2dbWlm3ZsoUxJvmdvnz5MjMwMOAzWr169erFjh07xhiTzJyRkSGoQZEvMzMzY1OnTuUGvtUqKipiZmZmPKWq39y5c9mCBQv4jtFk27ZtYwoKCuyTTz5hq1atYqtWrWKffPIJU1RUZDt27OA7XqPRYLIWCAwMxMyZM1FeXg7GGM6fP49du3YhJiZGsL/kv//+e2RlZcHIyAg9evSQ6kIWwkQLr/PPP/8AALp168ZzkvrJ6uecmZlZ57SKWlpaePr0afsHaoS7d+/C3Nxcql0sFqOqqoqHRK+Xm5sLBQUFDB48GL/88gsMDQ0BvOjGf/W8qhBUV1cjMTERx44dE/ypp5dFRUVh2bJlCAgI4Npmz56N2NhYREZGYuLEiTymazwq1C0wffp0qKqqIjg4GGVlZZg4cSKMjIywatUqfPrpp3zHq9Or01zKCrFYjG+++QYrVqxASUkJAEBDQwNfffUVvv76a8jJCessjqx+zoaGhsjKypKa7e3UqVPo2bMnP6Few9LSEidPnpSa3nTfvn11npoSApFIhCNHjiAoKAgODg7Yv38/+vXrx3esetWeegKAW7duSTwm5MGROTk58PDwkGofPXo0Fi9ezEOiZuL7kL6jKC0tZffv3+c7Roe1cOFCpqenx9asWcNdExkfH8/09PQEOZOTrIqOjmaWlpbs3LlzTENDg508eZJt376d6enpsdWrV/Mdr0779+9nWlpabOnSpUxNTY0tX76cTZ8+nSkpKbGjR4/yHa9OIpGI+/di4cKFTFVVlW3bto0VFhbKzKyGsqBXr14sISFBqn3t2rXM3Nych0TNQ4W6BcrKylhpaSl3Pzc3l61cuZL9/vvvPKZ6vSdPnrD169ezhQsXcudQL126xP755x+ek9Wva9eu7MCBA1Lt+/fvZ0ZGRjwk6pjEYjH75ptvWKdOnbipWlVUVFhwcDDf0RqUlpbGXF1dmZ6eHlNVVWUDBw4U9H+HcnJyEj/st23bxlRUVJiPjw8V6la0Zs0apqSkxGbMmMG2bt3Ktm7dyj7//HOmrKxcZwEXKro8qwWGDx8OT09PzJgxA0+fPsVbb70FJSUlPHz4ELGxsfjiiy/4jijl2rVrcHV15aayzMzMRM+ePREcHIy8vDxs3bqV74h1UlFRwbVr19CnTx+J9szMTNja2gpuesuamhqsXLmy3kUXHj9+zFOyxqmsrERWVhZKSkpgaWkJdXV1viN1KHJycigsLIS+vj7XdvbsWXz00UcoKioS5BUDFy9erPf7LMTFWmr9/PPPWLFihcT13/PmzRPkhFT14vuXgizr0qULu379OmOMsfXr1zNra2tWU1PD9u7dK9iFF95//31uKsCXR8iePn2a9ejRg8dkDevfvz+bNWuWVLu/vz9zcnLiIVHDQkJCWNeuXdl3333HVFRUWGRkJPP19WVdunRhq1at4jteh+Lr68uOHz/Od4xWUVhYyFJTU/mOIWXXrl1MUVGRffjhh0xJSYl9+OGHrE+fPkxLS4tNnTqV73j18vb2ZidOnOA7RotRoW6Bl1caGj9+PFuyZAljjLG8vDymqqrKZ7R6aWpqsqysLMaYZKHOzc1lysrKfEZrUGpqKuvUqROzsLBg06ZNY9OmTWMWFhZMXV2dpaWl8R1PSs+ePdnBgwcZYy8+59rPfNWqVczLy4vPaA0qKSlhwcHBzNnZmfXq1YuZmZlJ3IRo9OjRTFlZmXXr1o0FBQWxK1eu8B3ptcLDw1lKSopUe0lJCQsPD+chUcOsrKzY999/zxj7378bYrGY+fn5sdDQUJ7T1W/MmDFMUVGRmZubs6ioKHb37l2+IzULFeoWsLKyYqtWrWJ5eXlMU1OTnTlzhjHG2MWLFwV7zamenh67fPkyY0yyUB89epR169aNz2ivdffuXbZ48WLm6enJPD092ddffy3Y//DU1NS4H3GGhobs0qVLjDHGsrOzmaamJp/RGvTpp5+yrl27svnz57OVK1eyuLg4iZtQPX78mK1bt465uLgwOTk5ZmlpyaKiotjt27f5jlan2mVaV6xYIdEu1MFkampq3Gepo6PDrl27xhhj7MaNG8zQ0JDHZK/34MEDtmLFCmZtbc0UFBSYu7s727t3L6usrOQ7WqNRoW6BH3/8kSkqKjI5OTnm6urKtUdHRzN3d3cek9XP19eXjR07llVWVjJ1dXWWk5PD7ty5w+zs7Lh1fIXio48+4lb12rJli9TkEELWp08fdu7cOcYYYwMHDmQxMTGMMcZ2797N9PT0+IzWIC0tLXbq1Cm+Y7RIfn4+W7ZsGevbty+Tl5fnO06dRCIR2717N+vSpQubOnUqq6ioYIwJt1AbGxtzxdnKyopbm/rMmTOC/uH5qkuXLjF/f3+moqLCdHV12dy5c2ViVT4q1C1UUFDALl++zGpqari2P/74g2VkZPCYqn5Pnz5lrq6uTFtbm8nLyzMTExOmqKjIhgwZwkpKSviOJ0FRUZHdu3ePMSY9SlboFixYwKKiohhjL4qzgoICMzc3Z0pKSoKe4cnU1JTduHGD7xjNVllZyX7++Wf28ccfMxUVFcFeEVB7eVZWVhazsLBgzs7O7P79+4It1F5eXtzRf0REBNPT02PTp09nPXr0YB999BHP6Rrn3r17bOnSpeytt95inTp1Yt7e3uz9999nCgoKLDY2lu94DaJR361EFmbLetmpU6dw7do1lJSUwN7eHq6urnxHkmJtbQ17e3sMGzYMPj4+WL16NTQ1Nevc1tvbu53TNc25c+e4RRfqmoBBKLZv344DBw5gy5YtUFNT4ztOox0/fhw7d+7ETz/9BLFYDE9PT0yaNAnvvfeeICfkkJeXR0FBAfT19VFcXIxPPvkEf/31FxISEjB69GjBjfp+/PgxysvLYWRkBLFYjGXLlnHf5+DgYHTu3JnviHWqqqrCL7/8gk2bNuHo0aOwtrbG9OnTMXHiRO7fkp9//hnTpk3DkydPeE5bPyrULSBrs2UBL9ZEFvKydC87ffo0vvrqK2RnZ+Px48fQ0NCo8x9dkUgk+MudhMzOzk7ic83KygJjDKamplBUVJTYVohTnxobG+Px48dwd3fHpEmT4OHhwa1JLVSvXp4lFosxd+5crF27FmKxWHCFWlbp6upCLBbDy8sLfn5+sLW1ldrm6dOnsLOzw+3bt9s/YCPRFKIt8PXXX2Pjxo1YunQpBg4cCODFkeqSJUtQXl6OqKgonhNKMzU1xaBBgzB58mSMGzdOsL+EAWDgwIE4d+4cgBf/sN26dUviulMh6969O4YOHQoXFxcMHToUvXr14jtSvWR1utNaS5Yswfjx46Gtrc13lEbbtGkTtLS0uPtycnJYvXo17OzskJaWxmOyunl7e2PYsGEYMmSIoL/Lr1q5ciXGjx/f4PrT2tragi7SAB1Rt4iRkRHXVfWyAwcO4Msvv8Tdu3d5Sla/K1euYOfOndi9ezeKiorg7u6OyZMnC/IoxNPTE5s3b4ampia2bNmCTz75BKqqqnzHapTt27cjLS0NqampyMrKgrGxMVxcXLjCTev6tg1ZOwUlK6ZPn460tDSJ73LtD1H6Lrc9KtQtIGuzZb2MMYbU1FSp83qJiYl8R+MoKSnhzp076Nq1q8Q5PVlTUFCAEydO4ODBg9izZ4+guzYvXLgAsVgMJycnifY//vgD8vLycHR05ClZ/WTlFNTq1avxf//3f1BRUcHq1avr3U4kEmHWrFntmKzx7t69i7S0NJw4cQInTpzArVu30LVrV+4HEmkbVKhbwMnJCU5OTlL/0c2aNQsXLlzgum2F7vLly/D19cW1a9cEVUBkfTBZWVkZTp06hdTUVBw/fhxXrlyBhYUFhg4dipUrV/Idr079+/fH/PnzMW7cOIn2pKQkfPvtt/jjjz94Sla/RYsWYePGjQgPD5c6BeXn5yeYU1BmZma4ePEiunTpAjMzs3q3E4lEyMnJacdkjVf7nT5+/DhSU1Nx+fJlWFpa4sqVK3xH69CoULfAiRMnMGrUKHTv3h3Ozs4AXszXm5+fj99++w2DBw/mOWH9/vnnH+zcuRM7d+7E9evX4ezsjEmTJmHGjBl8R+OcOXMGgYGBMjmYbMCAARKF2cXFBUOGDBH0mAAAUFdXx7Vr16SWtLx9+zasra3x77//8pSsfrJ4Cupltf8EC3F0eq3FixcjNTWV+07Xdn3Lwne6I6BC3UL37t1DfHw8bt68CeDFhO9ffvkljIyMeE5Wt3Xr1mHnzp04deoULCwsMGnSJEycOFFqLV+hqWsRAyHT0dGBnJwchg8fjqFDh2Lo0KFSp0iEqEuXLjh48CD3w7PWmTNnMGrUKEFewiKrp6A2btyIlStX4u+//wYA9O7dG3PnzsX06dN5TiZNTk4Oenp6CAgIgKenp0x8lzsSKtRvGBMTE3h5eWHSpEmwsbHhO06j3blzB3l5eVi3bh1ycnLw448/wtjYGNu2bYOZmRkGDRrEd0QJjDH8+eefSE1NxYkTJ5CWlgYlJSW4uLhg2LBh8PPz4ztinby8vFBQUIADBw5wo5KfPn2KsWPHQl9fH3v37uU5oTRZPAUVGhqK2NhYzJo1S6I37vvvv0dAQAAiIiJ4TigpPT0dJ06cQGpqKk6ePMl9l2XpR6gso0LdRNeuXWv0ttbW1m2YpHkYYzh16pTMFLxaP/30Ez777DNMmjQJ27Ztw40bN9CzZ098//33+O233/Dbb7/xHbFejDFcunQJ33//PXbs2CHowWR3797FkCFD8OjRI9jZ2QEArl69CgMDAyQnJwvyGvz6TkHl5eXh8OHDgjwFpaenh9WrV8PLy0uifdeuXZg1axYePnzIU7LGSU9Px8qVKwX/fe4o6DrqJrK1tYVIJMLrft+IRCJBfnmTkpK4gnf58mVUVFQAAJ49e4bo6GjBFrxvvvkGCQkJ8Pb2xu7du7n2gQMH4ptvvuExWd0uX76M1NRUpKam4tSpU/j3339hZWWFWbNmwcXFhe949TI2Nsa1a9ewY8cOpKenQ1VVFT4+PvDy8pKa/EQoXFxckJmZibVr13JrDnt6egr6FFRVVVWdI+gdHBxQXV3NQ6KGMcZw5coVie90cXExrK2tBf197ijoiLqJ7ty50+hthXje187ODgEBAfD29oaGhgbS09PRs2dPXLlyBSNGjEBhYSHfEeukpqaGGzduwNTUVCJ3Tk4OLC0tUV5ezndECQoKCrCzs+OunR4yZIjEBBekdZWXl+PatWt48OABxGKxxGOvDjITglmzZkFRURGxsbES7UFBQXj+/Dni4+N5Sla3zp07o6SkBDY2NlyX9+DBg2VqkhlZRkfUTfRy8Y2JiYGBgQGmTZsmsU1iYiKKioqwYMGC9o73WpmZmRgyZIhUu5aWFp4+fdr+gRrJ0NAQWVlZMDU1lWg/deqU1AhlvtXU1CApKQmDBw+WyRGxf//9N44fP15n0QsNDeUpVf2OHDkCb29vPHr0SKqnS6g9W8CLwWRHjx7Fu+++C+DFtep5eXnw9vZGYGAgt92rxZwP27dvx+DBg+u9PJK0LSrULVA7gvpVb7/9Nj799FNBFmpZKngv8/Pzw5w5c5CYmAiRSIR79+7h7NmzCAoKQkhICN/xJMjLy+OTTz5BRkaGzBXq9evX44svvoCuri4MDQ0lLhkSiUSCLNSzZs3C+PHjERoaCgMDA77jNMr169dhb28PAMjOzgbwYl5qXV1dXL9+ndtOKJdsjRo1ivubZn/jQbus0dVBKSsrs5ycHKn27OxspqyszEOi14uOjmaWlpbs3LlzTENDg508eZJt376d6enpsdWrV/Mdr15isZh98803rFOnTkwkEjGRSMRUVFRYcHAw39Hq5ODgwI4dO8Z3jCbr3r07W7p0Kd8xmkRDQ4NlZWXxHaNDq6mpYeHh4UxTU5PJyckxOTk5pqWlxSIiIiSW+CVtgwp1C5ibm7Nt27ZJtW/dupWZmZnxkOj1ZK3gvaqiooL99ddf7I8//mD//vsv33HqdfjwYWZra8t+/fVXdu/ePfbs2TOJm1BpaGiw7OxsvmM0iY+PD9uwYQPfMTq0hQsXMj09PbZmzRqWnp7O0tPTWXx8PNPT02OLFy/mO16HR4PJWmDZsmVYtmwZli9fjvfeew8AkJKSgvnz5+Orr77CokWLeE5Yv8rKSmRlZaGkpASWlpZQV1fnO1KH8vL80i93XzLGBH3e1NfXF/369RPUDHWvU1ZWhvHjx0NPTw9WVlZSo9Nnz57NU7KOQ9Znf5N1dI66BebNm4dHjx7hyy+/RGVlJYAXsyQtWLBA0EUaeLHghaWlJd8xOqzjx4/zHaFZzM3NERISgnPnzslM0du1axeOHj0KFRUVpKamSp1XF2JmWfP48WP07dtXqr1v376Cm763I6Ij6lZQUlKCjIwMqKqqonfv3oJbLpKQxpLFxSIMDQ0xe/ZsLFy4UDArZXU0sjj7W0dChZqQNvL06VNs3LiRm4Tj7bffxrRp0+h66lamo6ODCxcuoFevXnxH6bBkeQGijoAKNSFt4OLFi3Bzc4Oqqir69+8P4MVaz8+fP8fRo0e5S3OEIDAwEJGRkejUqZPE9buvEolEWLFiRTsma5yAgADo6elh8eLFfEfpsPLy8qCgoFDnAkTV1dXo3r07zwk7NirUhLSBwYMHw9zcHOvXr4eCwouhINXV1Zg+fTpycnKQlpbGc8L/GTZsGH7++Wdoa2tj2LBh9W4nEonw3//+tx2TNc7s2bOxdetW2NjYwNraWuq8uhAmDJF18vLyKCgokFq97tGjR9DX1xfs4MiOggo1IW1AVVUVV65ckRqAc+PGDTg6OqKsrIynZB2PLP64kDX1LTN7584dWFpaorS0lKdkbwYa9U1IG9DU1EReXp5Uoc7Pz4eGhgZPqTomWR1hLwtqT4XUzkqnpqbGPVZTU4M//vgDtra2PKV7c1ChJqQNTJgwAb6+vvjuu+8wYMAAAMDp06cxb948qaUNCRGqK1euAPjf+upKSkrcY0pKSrCxsUFQUBBf8d4Y1PVNSCu5du0a3nnnHcjJyaGyshLz5s1DQkICt2yhoqIivvjiCyxdupQu4SMyxcfHB6tWraJFOXhChZqQVvLygJuePXviwoULUFVV5RZd6NWrl0TXISGENAZ1fRPSSrS1tXH79m3o6+sjNzcXYrEYampqsLKy4jsaIUSGUaEmpJV8/PHHcHFxQdeuXSESieDo6Ah5efk6txXiDF+EEGGiQk1IK/nhhx/g6emJrKwszJ49G35+fjTCmxDSYnSOmpA24OPjg9WrV1OhJoS0GBVqQgghRMBoqRlCCCFEwKhQE0IIIQJGhZoQQggRMCrUhBBCiIBRoSaEEEIEjAo1IYQQImBUqAkhhBABo0JNCCGECNj/AziNpZr5Sbj4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar( x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14944211-b311-4c55-a321-7395ae7e01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-K sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79eaf601-7fa3-4d75-bb9e-5d1dcd79aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b76fe886-9634-4342-916e-0405cbb46a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7500, 6.2800, 4.5100]) tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(top_logits, top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1837b880-f656-4026-876e-3994acbfd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float(\"-inf\")),\n",
    "    other = next_token_logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17616bc1-90b0-40d7-a980-52a7d4fd49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa23222c-25fc-457f-89e8-09442c31fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(new_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d516321-7902-408a-a6c3-38e32146304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df514d4e-b6b2-4d59-8b84-2ddb5487692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([50256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "721bd0c0-d2e9-42b8-8c91-038c69752af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None, eos_id=None):\n",
    "    \n",
    "    # Get the device the model's parameters are on\n",
    "    device = next(model.parameters()).device\n",
    "    # Ensure the initial input is on the same device as the model\n",
    "    idx = idx.to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop idx to the last context_size tokens\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions from the model\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the logits for the last time step\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply top-k filtering if specified\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            # Set all logits not in the top-k to negative infinity\n",
    "            logits[logits < top_logits[:, [-1]]] = float('-inf')\n",
    "\n",
    "        # Apply temperature scaling and sample the next token\n",
    "        if temperature > 0.0:\n",
    "            # Apply temperature scaling\n",
    "            scaled_logits = logits / temperature\n",
    "            probs = torch.softmax(scaled_logits, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # Greedily select the most likely token (if temperature is 0)\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Stop if the end-of-sequence token is generated\n",
    "        if eos_id is not None and idx_next == eos_id:\n",
    "            break\n",
    "            \n",
    "        # Append the sampled token to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "639acc4d-3568-47b9-9cbb-4a417f75a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you causing Sed Pall household.] pops320 Jacksonvillegger Â£ discouraged synergy StarcraftCrossallic\n"
     ]
    }
   ],
   "source": [
    "gpt = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpt.to(device)\n",
    "\n",
    "# The tokenizer is used on the CPU\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Generate text\n",
    "torch.manual_seed(123) # for reproducibility\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    # Move the input tensor to the same device as the model\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38245ad7-f8ef-4cb0-be18-cb4aeb3b458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "I felt to Mrs. . . .\n",
      "\n",
      "Well--\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    #temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0fdaf2b-f2ad-42f4-bf5e-3814f8679616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youaldi benchmark phrase as chest of tea Seas nominations couldfcskirts renters then Sears\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    #top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "84435331-f0eb-4946-a533-1650f3e6e8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you like to through my bravrowed by a smile that lifted the frame last\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "86c5ada7-d0e6-432d-9013-a6dee886b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and saving model weights with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c69dd205-fd63-474f-9e64-4a5e7b7c0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5b3c4f1-e25b-4648-b668-d8de5f801b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, #Vocabulary size\n",
    "    \"context_length\": 256, #Context length\n",
    "    \"emb_dim\": 768, #Embedding Dimension\n",
    "    \"n_heads\": 12, #Number of attention heads\n",
    "    \"n_layers\": 12, #Number of layers\n",
    "    \"drop_rate\": 0.1, #Dropout rate\n",
    "    \"qkv_bias\": False #Query-Key-Value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d9d2993-e6f9-4c73-bb54-b11fa0a4eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanis\\AppData\\Local\\Temp\\ipykernel_16876\\761034928.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3407d8a-3fcd-449e-b4d8-5fbba3fc6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c95e48d5-5355-4e7c-ae68-bc5206f4fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.16.1\n",
      "tqdm version: 4.66.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d086051-96eb-43a4-92e2-6c28bb5cf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e057bd0e-9213-4d4e-9d89-068643aeb390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\checkpoint) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\checkpoint\n",
      "Failed to download from both primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\checkpoint) and backup URL (https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\checkpoint).\n",
      "Check your internet connection or the file availability.\n",
      "For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\n",
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\encoder.json) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\encoder.json\n",
      "Failed to download from both primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\encoder.json) and backup URL (https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\encoder.json).\n",
      "Check your internet connection or the file availability.\n",
      "For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\n",
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\hparams.json) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\hparams.json\n",
      "Failed to download from both primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\hparams.json) and backup URL (https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\hparams.json).\n",
      "Check your internet connection or the file availability.\n",
      "For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\n",
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\model.ckpt.data-00000-of-00001) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "Failed to download from both primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models\\124M\\model.ckpt.data-00000-of-00001) and backup URL (https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\\124M\\model.ckpt.data-00000-of-00001).\n",
      "Check your internet connection or the file availability.\n",
      "For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f09bb888-1d35-4939-9052-411ffcb7b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2ddf70d8-19f8-4a54-9d09-59fa1073f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d44abcad-84bc-4f7f-b139-610118d48bdc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "afa9b370-3615-43f9-92f9-979b7161ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model configurations in a dictionary for compactness\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, #Vocabulary size\n",
    "    \"context_length\": 1024, #Context length\n",
    "    \"emb_dim\": 768, #Embedding Dimension\n",
    "    \"n_heads\": 12, #Number of attention heads\n",
    "    \"n_layers\": 12, #Number of layers\n",
    "    \"drop_rate\": 0.1, #Dropout rate\n",
    "    \"qkv_bias\": False #Query-Key-Value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-x1 (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "#Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\" #Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b63a3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87964a1e-6bda-4e33-bac8-7a5233aa085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left,right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5378d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07b9b9f2-7f66-4fab-a85d-82ad7a0307d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"]) [\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"]) [\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "        \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ea33e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you through every step with an inexorabilible force. It has no effect\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
